{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# currentdir = os.path.dirname(os.path.realpath(__file__))\n",
    "# parentdir = os.path.dirname(os.path.dirname(currentdir))\n",
    "# sys.path.append(parentdir)\n",
    "\n",
    "from utils.Empirical.architectures import ARCHITECTURES\n",
    "from utils.Empirical.datasets import DATASETS\n",
    "\n",
    "from utils.Empirical.utils_ensemble import AverageMeter, accuracy, test, copy_code, requires_grad_, evaltrans\n",
    "from utils.Empirical.datasets import get_dataset\n",
    "from utils.Empirical.architectures import get_architecture\n",
    "from train.Empirical.trainer import Naive_Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = get_dataset('cifar10', 'train')\n",
    "test_dataset = get_dataset('cifar10', 'test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=128,\n",
    "                              num_workers=4 )\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=128,\n",
    "                             num_workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 144\n"
     ]
    }
   ],
   "source": [
    "samp_cont = 0\n",
    "mu , sigma = 0,0\n",
    "for i, (inputs, targets) in enumerate(train_loader):\n",
    "    # inputs, targets =inputs.to(device), targets.to(device)          \n",
    "    batch_size = inputs.size(0)\n",
    "    pixel = inputs.size(1)*inputs.size(2)*inputs.size(3)\n",
    "    idx_list = np.arange(batch_size)\n",
    "\n",
    "    samp_list = np.random.choice(idx_list, size= np.int64( np.ceil(0.02*batch_size) ), replace=False,p = None)\n",
    "    samp_num = len(samp_list)\n",
    "    \n",
    "    # for idx in samp_list:\n",
    "    curr_mu = torch.mean(inputs[samp_list])\n",
    "    curr_sigma = torch.var(inputs[samp_list]) \n",
    "    \n",
    "    mu = (mu*samp_cont + curr_mu*samp_num)/(samp_cont + samp_num)\n",
    "    sigma = (sigma*samp_cont + curr_sigma*samp_num)/(samp_cont + samp_num)\n",
    "    samp_cont = samp_cont + samp_num\n",
    "lower_b =np.int64(np.ceil( (mu - 2*sigma)*255 ))\n",
    "upper_b =np.int64(np.ceil( (mu + 2*sigma)*255 ))\n",
    "\n",
    "print(lower_b,upper_b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "randm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b924798614629fa895bbe9550b7835837bd0e83c26f08873ae4b84aca012077a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
